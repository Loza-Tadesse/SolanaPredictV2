{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc720f7",
   "metadata": {},
   "source": [
    "# River Linear Regression\n",
    "# Import Dependencies\n",
    "This notebook adapts the shared four-hour preprocessing template to train an online `river` linear regression model on Solana minute-ahead price deltas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee2c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "try:\n",
    "    from river import compose, linear_model, optim, preprocessing\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\"Install the 'river' package to run this notebook.\") from exc\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Lock seeds for numpy, random, and python hashing.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        if (candidate / \"src\" / \"mlProject\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Unable to locate project root containing src/mlProject\")\n",
    "\n",
    "\n",
    "def ensure_pythonpath(root: Path) -> None:\n",
    "    src_path = root / \"src\"\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.append(str(src_path))\n",
    "\n",
    "\n",
    "def configure_environment(seed: int = 42) -> Path:\n",
    "    set_seed(seed)\n",
    "    project_root = find_project_root()\n",
    "    ensure_pythonpath(project_root)\n",
    "    return project_root\n",
    "\n",
    "\n",
    "PROJECT_ROOT = configure_environment()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86de277",
   "metadata": {},
   "source": [
    "# Fetch Last Four Hours of 1-Minute Data\n",
    "We gather a 240-point SOL/USDT minute window so the online learner consumes the same information stream as the Streamlit service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRYPTOCOMPARE_URL = \"https://min-api.cryptocompare.com/data/v2/histominute\"\n",
    "\n",
    "\n",
    "def fetch_minute_data(symbol: str = \"SOL\", quote: str = \"USD\", minutes: int = 240) -> pd.DataFrame:\n",
    "    params = {\n",
    "        \"fsym\": symbol.upper(),\n",
    "        \"tsym\": quote.upper(),\n",
    "        \"limit\": minutes,\n",
    "        \"aggregate\": 1,\n",
    "    }\n",
    "    response = requests.get(CRYPTOCOMPARE_URL, params=params, timeout=15)\n",
    "    response.raise_for_status()\n",
    "    payload = response.json()\n",
    "    if payload.get(\"Response\") != \"Success\":\n",
    "        raise RuntimeError(f\"CryptoCompare API error: {payload.get('Message')}\")\n",
    "\n",
    "    frame = pd.DataFrame(payload[\"Data\"][\"Data\"])\n",
    "    frame[\"datetime\"] = pd.to_datetime(frame[\"time\"], unit=\"s\", utc=True)\n",
    "    frame = frame.rename(\n",
    "        columns={\n",
    "            \"close\": \"price\",\n",
    "            \"volumefrom\": \"volume\",\n",
    "            \"volumeto\": \"market_cap\",\n",
    "        }\n",
    "    )\n",
    "    frame = frame[[\"datetime\", \"price\", \"volume\", \"market_cap\"]]\n",
    "    frame = frame.set_index(\"datetime\").sort_index()\n",
    "    return frame\n",
    "\n",
    "\n",
    "raw_minute_df = fetch_minute_data()\n",
    "raw_minute_df.tail()\n",
    "raw_minute_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0169d1",
   "metadata": {},
   "source": [
    "# Preprocess & Align Time Series\n",
    "We fill tiny gaps and enforce a continuous UTC minute index before engineering indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6544387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_minute_frame(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    cleaned = frame[~frame.index.duplicated(keep=\"last\")]\n",
    "    full_index = pd.date_range(\n",
    "        end=cleaned.index.max(),\n",
    "        periods=len(cleaned),\n",
    "        freq=\"1min\",\n",
    "        tz=\"UTC\",\n",
    "    )\n",
    "    aligned = cleaned.reindex(full_index)\n",
    "    aligned = aligned.interpolate(method=\"time\").bfill().ffill()\n",
    "    return aligned\n",
    "\n",
    "\n",
    "aligned_minute_df = align_minute_frame(raw_minute_df)\n",
    "aligned_minute_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c1ba91",
   "metadata": {},
   "source": [
    "# Feature Engineering Pipeline\n",
    "We invoke the existing indicator stack, craft minute-ahead labels, and compute residual deltas to stabilize the online optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a700e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.entity.config_entity import DataIngestionConfig\n",
    "from mlProject.components.crypto_data_ingestion import CryptoDataIngestion\n",
    "\n",
    "TEMP_ARTIFACT_DIR = PROJECT_ROOT / \"artifacts\" / \"notebook_tmp\"\n",
    "TEMP_ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ingestion_config = DataIngestionConfig(\n",
    "    root_dir=TEMP_ARTIFACT_DIR,\n",
    "    source_url=\"\",\n",
    "    local_data_file=TEMP_ARTIFACT_DIR / \"minute_data.zip\",\n",
    "    unzip_dir=TEMP_ARTIFACT_DIR / \"unzipped\",\n",
    ")\n",
    "\n",
    "ingestor = CryptoDataIngestion(ingestion_config)\n",
    "feature_enriched_df = ingestor.add_technical_indicators(aligned_minute_df.copy())\n",
    "feature_enriched_df = ingestor.create_prediction_targets(feature_enriched_df)\n",
    "feature_enriched_df = feature_enriched_df.dropna(subset=[\"target_price_1min\"]).fillna(0.0)\n",
    "\n",
    "feature_enriched_df[\"target_delta_1min\"] = feature_enriched_df[\"target_price_1min\"] - feature_enriched_df[\"price\"]\n",
    "\n",
    "CLEAN_FEATURES = [\n",
    "    \"price\", \"volume\", \"market_cap\",\n",
    "    \"sma_7\", \"sma_14\", \"sma_30\",\n",
    "    \"ema_7\", \"ema_14\",\n",
    "    \"macd\", \"macd_signal\", \"macd_histogram\",\n",
    "    \"rsi\",\n",
    "    \"bb_middle\", \"bb_upper\", \"bb_lower\",\n",
    "    \"price_change_1h\", \"price_change_24h\", \"price_change_7d\",\n",
    "    \"volume_sma\", \"volume_ratio\",\n",
    "    \"volatility\",\n",
    "    \"high_14d\", \"low_14d\",\n",
    "    \"price_position\",\n",
    "]\n",
    "\n",
    "features = feature_enriched_df[CLEAN_FEATURES].values\n",
    "target_prices = feature_enriched_df[\"target_price_1min\"].values\n",
    "base_prices = feature_enriched_df[\"price\"].values\n",
    "target_deltas = feature_enriched_df[\"target_delta_1min\"].values\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Target deltas shape: {target_deltas.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f06b3",
   "metadata": {},
   "source": [
    "# Train River Linear Model\n",
    "We iterate over the training window, updating a standard-scaler-plus-linear-regression pipeline via stochastic gradient descent, then score the held-out tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c321d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_river_model():\n",
    "    optimizer = optim.SGD(learning_rate=optim.learning_rate.InverseTime(initial_rate=0.05))\n",
    "    regressor = linear_model.LinearRegression(optimizer=optimizer, intercept_init=0.0)\n",
    "    return compose.Pipeline(preprocessing.StandardScaler(), regressor)\n",
    "\n",
    "def to_feature_dict(row: np.ndarray) -> dict[str, float]:\n",
    "    return {feature: float(value) for feature, value in zip(CLEAN_FEATURES, row)}\n",
    "\n",
    "split_index = int(len(features) * 0.8)\n",
    "train_features = features[:split_index]\n",
    "train_targets = target_deltas[:split_index]\n",
    "valid_features = features[split_index:]\n",
    "valid_targets = target_prices[split_index:]\n",
    "valid_base = base_prices[split_index:]\n",
    "\n",
    "river_model = build_river_model()\n",
    "for row_values, target in zip(train_features, train_targets, strict=False):\n",
    "    river_model.learn_one(to_feature_dict(row_values), float(target))\n",
    "\n",
    "if len(valid_features) == 0:\n",
    "    print(\"Validation window empty; gather more data before scoring.\")\n",
    "else:\n",
    "    delta_valid_pred = [\n",
    "        river_model.predict_one(to_feature_dict(row_values))\n",
    "        for row_values in valid_features\n",
    "    ]\n",
    "    price_valid_pred = valid_base + np.array(delta_valid_pred)\n",
    "    mae = mean_absolute_error(valid_targets, price_valid_pred)\n",
    "    rmse = float(np.sqrt(mean_squared_error(valid_targets, price_valid_pred)))\n",
    "    r2 = r2_score(valid_targets, price_valid_pred)\n",
    "    print(f\"Validation MAE : {mae:.6f}\")\n",
    "    print(f\"Validation RMSE: {rmse:.6f}\")\n",
    "    print(f\"Validation R^2 : {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fba953",
   "metadata": {},
   "source": [
    "# Evaluate Predictions\n",
    "We compare the online model's reconstructed price path with the actual tail to ensure the incremental learner stays calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(valid_features) > 0:\n",
    "    valid_timestamps = feature_enriched_df.index[split_index:]\n",
    "    plt.figure()\n",
    "    plt.plot(valid_timestamps, valid_targets, label=\"Actual\", linewidth=2)\n",
    "    plt.plot(valid_timestamps, price_valid_pred, label=\"River Linear\", linewidth=2)\n",
    "    plt.title(\"River Linear Minute-Ahead Forecast\")\n",
    "    plt.xlabel(\"Timestamp\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
