{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a877c93",
   "metadata": {},
   "source": [
    "# SGDRegressor\n",
    "# Import Dependencies\n",
    "This notebook retraces the four-hour Solana feature engineering flow and trains an `SGDRegressor` on minute-ahead price deltas using the same structure as the legacy Random Forest walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7d84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"Set deterministic seeds for numpy, random, and Python hashing.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"Locate the repository root by searching for src/mlProject.\"\"\"\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        if (candidate / \"src\" / \"mlProject\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Unable to locate project root containing src/mlProject\")\n",
    "\n",
    "\n",
    "def ensure_pythonpath(root: Path) -> None:\n",
    "    \"\"\"Make sure the project's src directory is importable.\"\"\"\n",
    "    src_path = root / \"src\"\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.append(str(src_path))\n",
    "\n",
    "\n",
    "def configure_environment(seed: int = 42) -> Path:\n",
    "    \"\"\"Set global seed, find root, and extend sys.path.\"\"\"\n",
    "    set_seed(seed)\n",
    "    project_root = find_project_root()\n",
    "    ensure_pythonpath(project_root)\n",
    "    return project_root\n",
    "\n",
    "\n",
    "PROJECT_ROOT = configure_environment()\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43973c15",
   "metadata": {},
   "source": [
    "# Fetch Last Four Hours of 1-Minute Data\n",
    "We re-use the CryptoCompare minute endpoint to collect a synchronized four-hour SOL/USDT window so the SGDRegressor sees the same inputs as the production pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRYPTOCOMPARE_URL = \"https://min-api.cryptocompare.com/data/v2/histominute\"\n",
    "\n",
    "\n",
    "def fetch_minute_data(symbol: str = \"SOL\", quote: str = \"USD\", minutes: int = 240) -> pd.DataFrame:\n",
    "    params = {\n",
    "        \"fsym\": symbol.upper(),\n",
    "        \"tsym\": quote.upper(),\n",
    "        \"limit\": minutes,\n",
    "        \"aggregate\": 1,\n",
    "    }\n",
    "    response = requests.get(CRYPTOCOMPARE_URL, params=params, timeout=15)\n",
    "    response.raise_for_status()\n",
    "    payload = response.json()\n",
    "    if payload.get(\"Response\") != \"Success\":\n",
    "        raise RuntimeError(f\"CryptoCompare API error: {payload.get('Message')}\")\n",
    "\n",
    "    frame = pd.DataFrame(payload[\"Data\"][\"Data\"])\n",
    "    frame[\"datetime\"] = pd.to_datetime(frame[\"time\"], unit=\"s\", utc=True)\n",
    "    frame = frame.rename(\n",
    "        columns={\n",
    "            \"close\": \"price\",\n",
    "            \"volumefrom\": \"volume\",\n",
    "            \"volumeto\": \"market_cap\",\n",
    "        }\n",
    "    )\n",
    "    frame = frame[[\"datetime\", \"price\", \"volume\", \"market_cap\"]]\n",
    "    frame = frame.set_index(\"datetime\").sort_index()\n",
    "    return frame\n",
    "\n",
    "\n",
    "raw_minute_df = fetch_minute_data()\n",
    "raw_minute_df.tail()\n",
    "raw_minute_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f2546",
   "metadata": {},
   "source": [
    "# Preprocess & Align Time Series\n",
    "We align the raw candles to a continuous UTC minute index, interpolating any gaps to maintain evenly spaced samples for the downstream feature pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ebc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_minute_frame(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    cleaned = frame[~frame.index.duplicated(keep=\"last\")]\n",
    "    full_index = pd.date_range(\n",
    "        end=cleaned.index.max(),\n",
    "        periods=len(cleaned),\n",
    "        freq=\"1min\",\n",
    "        tz=\"UTC\",\n",
    "    )\n",
    "    aligned = cleaned.reindex(full_index)\n",
    "    aligned = aligned.interpolate(method=\"time\").bfill().ffill()\n",
    "    return aligned\n",
    "\n",
    "\n",
    "aligned_minute_df = align_minute_frame(raw_minute_df)\n",
    "aligned_minute_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886d9247",
   "metadata": {},
   "source": [
    "# Feature Engineering Pipeline\n",
    "We enrich the aligned series with the project technical indicators, create minute-ahead targets, and compute price deltas that the SGDRegressor will learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.entity.config_entity import DataIngestionConfig\n",
    "from mlProject.components.crypto_data_ingestion import CryptoDataIngestion\n",
    "\n",
    "TEMP_ARTIFACT_DIR = PROJECT_ROOT / \"artifacts\" / \"notebook_tmp\"\n",
    "TEMP_ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ingestion_config = DataIngestionConfig(\n",
    "    root_dir=TEMP_ARTIFACT_DIR,\n",
    "    source_url=\"\",\n",
    "    local_data_file=TEMP_ARTIFACT_DIR / \"minute_data.zip\",\n",
    "    unzip_dir=TEMP_ARTIFACT_DIR / \"unzipped\",\n",
    ")\n",
    "\n",
    "ingestor = CryptoDataIngestion(ingestion_config)\n",
    "feature_enriched_df = ingestor.add_technical_indicators(aligned_minute_df.copy())\n",
    "feature_enriched_df = ingestor.create_prediction_targets(feature_enriched_df)\n",
    "feature_enriched_df = feature_enriched_df.dropna(subset=[\"target_price_1min\"]).fillna(0.0)\n",
    "\n",
    "feature_enriched_df[\"target_delta_1min\"] = feature_enriched_df[\"target_price_1min\"] - feature_enriched_df[\"price\"]\n",
    "\n",
    "CLEAN_FEATURES = [\n",
    "    \"price\", \"volume\", \"market_cap\",\n",
    "    \"sma_7\", \"sma_14\", \"sma_30\",\n",
    "    \"ema_7\", \"ema_14\",\n",
    "    \"macd\", \"macd_signal\", \"macd_histogram\",\n",
    "    \"rsi\",\n",
    "    \"bb_middle\", \"bb_upper\", \"bb_lower\",\n",
    "    \"price_change_1h\", \"price_change_24h\", \"price_change_7d\",\n",
    "    \"volume_sma\", \"volume_ratio\",\n",
    "    \"volatility\",\n",
    "    \"high_14d\", \"low_14d\",\n",
    "    \"price_position\",\n",
    "]\n",
    "\n",
    "features = feature_enriched_df[CLEAN_FEATURES].values\n",
    "target_prices = feature_enriched_df[\"target_price_1min\"].values\n",
    "base_prices = feature_enriched_df[\"price\"].values\n",
    "target_deltas = feature_enriched_df[\"target_delta_1min\"].values\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Target deltas shape: {target_deltas.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569fd03b",
   "metadata": {},
   "source": [
    "# Train SGDRegressor\n",
    "We split the series chronologically, scale inputs with a `StandardScaler`, and fit an `SGDRegressor` tuned for the same delta target the Streamlit pipeline consumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c3ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(len(features) * 0.8)\n",
    "X_train, X_valid = features[:split_index], features[split_index:]\n",
    "y_train = target_deltas[:split_index]\n",
    "y_valid = target_deltas[split_index:]\n",
    "base_valid = base_prices[split_index:]\n",
    "\n",
    "sgd_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\n",
    "            \"sgd\",\n",
    "            SGDRegressor(\n",
    "                loss=\"squared_error\",\n",
    "                penalty=\"l2\",\n",
    "                alpha=1e-4,\n",
    "                learning_rate=\"invscaling\",\n",
    "                eta0=1e-2,\n",
    "                power_t=0.25,\n",
    "                max_iter=2000,\n",
    "                tol=1e-4,\n",
    "                random_state=42,\n",
    "                shuffle=True,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    memory=None,\n",
    ")\n",
    "sgd_pipeline.fit(X_train, y_train)\n",
    "\n",
    "if len(X_valid) == 0:\n",
    "    print(\"Validation window empty; collect more data before evaluating.\")\n",
    "else:\n",
    "    delta_valid_pred = sgd_pipeline.predict(X_valid)\n",
    "    price_valid_pred = base_valid + delta_valid_pred\n",
    "    mae = mean_absolute_error(target_prices[split_index:], price_valid_pred)\n",
    "    rmse = float(np.sqrt(mean_squared_error(target_prices[split_index:], price_valid_pred)))\n",
    "    r2 = r2_score(target_prices[split_index:], price_valid_pred)\n",
    "    print(f\"Validation MAE : {mae:.6f}\")\n",
    "    print(f\"Validation RMSE: {rmse:.6f}\")\n",
    "    print(f\"Validation R^2 : {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf89cbb",
   "metadata": {},
   "source": [
    "# Evaluate Predictions\n",
    "We visualize the minute-ahead forecasts against ground truth to confirm the SGDRegressor tracks the delta dynamics before wiring the artifact into Streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7f0e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_valid) > 0:\n",
    "    valid_timestamps = feature_enriched_df.index[split_index:]\n",
    "    plt.figure()\n",
    "    plt.plot(valid_timestamps, target_prices[split_index:], label=\"Actual\", linewidth=2)\n",
    "    plt.plot(valid_timestamps, price_valid_pred, label=\"SGDRegressor\", linewidth=2)\n",
    "    plt.title(\"SGDRegressor Minute-Ahead Forecast\")\n",
    "    plt.xlabel(\"Timestamp\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
